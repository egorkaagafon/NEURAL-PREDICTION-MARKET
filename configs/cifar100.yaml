# ─── Neural Prediction Market — CIFAR-100 Config ───
# Same architecture, 100 classes instead of 10.

seed: 42
device: "cuda"

# ── Data ──
data:
  dataset: "cifar100"
  root: "./data"
  batch_size: 1024
  num_workers: 8
  augmentation: true
  persistent_workers: true
  prefetch_factor: 4

# ── Model ──
model:
  image_size: 32
  patch_size: 4
  embed_dim: 256
  depth: 6
  num_heads: 8
  num_agents: 16
  num_classes: 100     # ← auto-set from dataset, but explicit here
  dropout: 0.1

# ── Market ──
market:
  initial_capital: 1.0
  capital_lr: 0.1
  capital_decay: 0.9
  normalize_payoffs: true
  bet_temperature: 1.0
  feature_keep_prob: 0.7
  evolution_enabled: true
  evolution_interval: 5
  kill_fraction: 0.1
  mutation_std: 0.02
  diversity_weight: 0.3
  agent_aux_weight: 0.3
# ── Training ──
training:
  epochs: 200
  optimizer: "adamw"
  lr: 3.0e-4
  weight_decay: 0.05
  warmup_epochs: 10
  scheduler: "cosine"
  label_smoothing: 0.0
  gradient_clip: 1.0

# ── Performance (A100 optimizations) ──
performance:
  amp: true
  amp_dtype: "bfloat16"
  compile: true

# ── Logging ──
logging:
  log_dir: "./runs"
  log_interval: 50
  save_interval: 10
  tensorboard: true

# ── Evaluation ──
evaluation:
  ood_datasets: ["svhn"]   # CIFAR-10 becomes OOD when training on CIFAR-100
  volatility_eps: 0.05
  volatility_steps: 10
