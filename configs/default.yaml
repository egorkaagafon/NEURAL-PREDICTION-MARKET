# ─── Neural Prediction Market — Default Config ───
# All hyperparameters in one place for reproducibility.

seed: 42
device: "cuda"        # "cuda" or "cpu"

# ── Data ──
data:
  dataset: "cifar10"   # cifar10 | cifar100 | svhn
  root: "./data"
  batch_size: 512        # A100 can easily handle 512+ for CIFAR
  num_workers: 8
  augmentation: true
  persistent_workers: true   # keep workers alive between epochs
  prefetch_factor: 4         # batches prefetched per worker

# ── Model ──
model:
  # ViT backbone
  image_size: 32
  patch_size: 4
  embed_dim: 256
  depth: 6              # number of Transformer blocks
  num_heads: 8           # heads per block (standard attention)

  # NPM agents
  num_agents: 16         # independent classifier heads (traders)
  num_classes: 10
  dropout: 0.1

# ── Market ──
market:
  # Capital dynamics
  initial_capital: 1.0
  capital_lr: 0.1        # η for C_i ← C_i * exp(η * log p_i(y)) — higher = faster differentiation
  capital_ema: 0.99      # smooth capital (0.99 tracks faster than 0.999)
  min_capital: 1.0e-4    # bankruptcy threshold
  max_capital: 100.0     # cap to prevent runaway

  # Betting
  bet_temperature: 1.0   # temperature for bet sigmoid

  # Evolutionary selection
  evolution_enabled: true
  evolution_interval: 5  # epochs between selection rounds (give capital time to diverge)
  kill_fraction: 0.1     # bottom α% replaced
  mutation_std: 0.02     # noise added to cloned weights

  # Diversity bonus (anti-herding)
  diversity_weight: 0.3  # λ for KL-diversity regularizer (push agents apart)

# ── Training ──
training:
  epochs: 200
  optimizer: "adamw"
  lr: 3.0e-4
  weight_decay: 0.05
  warmup_epochs: 10
  scheduler: "cosine"
  label_smoothing: 0.0   # we rely on market dynamics instead
  gradient_clip: 1.0

# ── Performance (A100 optimizations) ──
performance:
  amp: true              # automatic mixed precision
  amp_dtype: "bfloat16"  # bf16 native on A100 (no scaler needed, more stable than fp16)
  compile: true          # torch.compile — ~20-40% speedup (PyTorch 2.0+)

# ── Logging ──
logging:
  log_dir: "./runs"
  log_interval: 50       # steps
  save_interval: 10      # epochs
  tensorboard: true

# ── Evaluation ──
evaluation:
  ood_datasets: ["cifar100", "svhn"]
  volatility_eps: 0.01   # ε for volatility probing
  volatility_steps: 5    # number of perturbation samples
