"""
Market aggregation â€” the Â«exchange floorÂ» that turns individual agent
predictions + bets + capital into a single ensemble prediction.

The market clearing price:

    P(y | x) = Î£_i  C_i Â· b_i(x) Â· p_i(y | x)
               â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                      Î£_i  C_i Â· b_i(x)

This is NOT a simple average â€” it is a capitalâ€‘weighted, betâ€‘weighted
combination where agents with more accumulated capital and higher
current confidence have proportionally more influence.
"""

from __future__ import annotations

import torch
import torch.nn.functional as F


class MarketAggregator:
    """Stateless helper that computes the market clearing price and
    individual agent payoffs.

    All methods are pure functions (no learnable parameters).
    """

    # ------------------------------------------------------------------
    @staticmethod
    def clearing_price(
        probs: torch.Tensor,     # [K, B, C]
        bets: torch.Tensor,      # [K, B]
        capital: torch.Tensor,   # [K]
    ) -> torch.Tensor:
        """Compute aggregate market prediction.

        Returns
        -------
        market_probs : Tensor [B, C]
        """
        K, B, C = probs.shape

        # Expand capital to [K, B, 1]
        cap = capital.view(K, 1, 1).expand(K, B, 1)
        bet = bets.unsqueeze(-1)            # [K, B, 1]

        weights = cap * bet                 # [K, B, 1]
        weighted = (weights * probs).sum(0) # [B, C]
        denom = weights.sum(0).clamp(min=1e-8)  # [B, 1]

        market_probs = weighted / denom     # [B, C]
        return market_probs

    # ------------------------------------------------------------------
    @staticmethod
    def compute_market_loss(
        market_probs: torch.Tensor,   # [B, C]
        targets: torch.Tensor,        # [B]  (long)
        label_smoothing: float = 0.0,
    ) -> torch.Tensor:
        """Crossâ€‘entropy loss on the market prediction (used for backprop
        through the backbone + agent weights)."""

        log_probs = torch.log(market_probs.clamp(min=1e-8))
        if label_smoothing > 0:
            C = market_probs.shape[-1]
            one_hot = F.one_hot(targets, C).float()
            smooth = one_hot * (1 - label_smoothing) + label_smoothing / C
            loss = -(smooth * log_probs).sum(dim=-1).mean()
        else:
            loss = F.nll_loss(log_probs, targets)
        return loss

    # ------------------------------------------------------------------
    @staticmethod
    def agent_payoffs(
        probs: torch.Tensor,          # [K, B, C]
        targets: torch.Tensor,        # [B]
        bets: torch.Tensor = None,    # [K, B]  (optional)
    ) -> torch.Tensor:
        """Perâ€‘agent betâ€‘weighted payoff (used for capital updates, NOT backprop).

        R_i = mean_over_batch [ b_i Â· log p_i(y_true) + (1 - b_i) Â· 0 ]

        If an agent bets b_iâ‰ˆ0 it neither gains nor loses capital
        ("safe haven" / cash position).  Only the fraction of capital
        that is actually staked is at risk.

        Without bets (backward compat): R_i = mean log p_i(y_true).

        Returns
        -------
        payoffs : Tensor [K]  â€” mean reward per agent for this batch.
        """
        K, B, C = probs.shape
        # Gather trueâ€‘class probabilities: [K, B]
        idx = targets.unsqueeze(0).expand(K, B).unsqueeze(-1)  # [K, B, 1]
        p_true = probs.gather(dim=2, index=idx).squeeze(-1)    # [K, B]
        log_p = torch.log(p_true.clamp(min=1e-8))              # [K, B]

        if bets is not None:
            # Betâ€‘weighted: staked fraction earns/loses, unstaked is safe
            log_p = bets * log_p   # [K, B]  â€” b_iâ‰ˆ0 â†’ payoffâ‰ˆ0

        payoffs = log_p.mean(dim=1)                             # [K]
        return payoffs

    # ------------------------------------------------------------------
    @staticmethod
    def diversity_loss(
        probs: torch.Tensor,   # [K, B, C]
    ) -> torch.Tensor:
        """Encourage agents to maintain diverse hypotheses.

        Penalise when all agents agree too much:
            L_div = - mean pairwise KL divergence

        Maximising diversity â‰ˆ minimising herding risk.
        """
        K, B, C = probs.shape
        # Mean KL between every pair (i, j)
        # For efficiency, we compare each agent to the ensemble mean.
        mean_probs = probs.mean(dim=0, keepdim=True)  # [1, B, C]
        # KL(p_i || mean)
        kl = (probs * (probs.clamp(min=1e-8).log() - mean_probs.clamp(min=1e-8).log()))
        kl = kl.sum(dim=-1).mean()  # scalar
        # We want to maximise KL â†’ so loss = -KL
        return -kl

    # ------------------------------------------------------------------
    @staticmethod
    def bet_calibration_loss(
        probs: torch.Tensor,     # [K, B, C]  â€” agent softmax predictions
        bets: torch.Tensor,      # [K, B]     â€” agent bet magnitudes (âˆˆ (0,1))
        targets: torch.Tensor,   # [B]        â€” true class labels
    ) -> torch.Tensor:
        """Calibrate bets: high when agent is correct, low when wrong.

        L_bet = BCE(b_i, ğŸ™[argmax p_i = y])

        This directly trains the bet signal to be informative.
        On easy samples: most agents correct â†’ high bets â†’ high liquidity.
        On hard/OOD samples: few agents correct â†’ low bets â†’ low liquidity.

        Returns
        -------
        loss : scalar Tensor
        """
        K, B, C = probs.shape
        # Which agents got the right answer?
        agent_preds = probs.argmax(dim=-1)                          # [K, B]
        correct = (agent_preds == targets.unsqueeze(0)).float()     # [K, B]
        # BCE between bets and correctness
        # Cast to float32 â€” binary_cross_entropy is unsafe under AMP autocast
        return F.binary_cross_entropy(bets.float(), correct)
